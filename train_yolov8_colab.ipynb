{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75fd0c92",
   "metadata": {},
   "source": [
    "## 1. Setup - Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b61793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install ultralytics\n",
    "!pip install ultralytics -q\n",
    "\n",
    "# Verify GPU availability\n",
    "import torch\n",
    "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83293fac",
   "metadata": {},
   "source": [
    "## 2. Upload Dataset\n",
    "\n",
    "**Option A: Upload ZIP file**\n",
    "- First, create a ZIP of your yolo_data folder locally\n",
    "- Then upload it using the file browser on the left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a5d3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create zip of yolo_data folder locally first:\n",
    "# On Windows: Compress-Archive -Path yolo_data -DestinationPath yolo_data.zip\n",
    "# Then upload yolo_data.zip to Colab\n",
    "\n",
    "# Uncomment and run if you uploaded yolo_data.zip\n",
    "# !unzip -q yolo_data.zip\n",
    "# print(\"Dataset extracted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37131e88",
   "metadata": {},
   "source": [
    "**Option B: Mount Google Drive**\n",
    "\n",
    "If you uploaded yolo_data.zip to Google Drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93137316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Copy dataset from Drive (adjust path as needed)\n",
    "# !cp /content/drive/MyDrive/yolo_data.zip .\n",
    "# !unzip -q yolo_data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dc51d7",
   "metadata": {},
   "source": [
    "## 3. Verify Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156b7ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Check dataset structure\n",
    "data_path = Path('yolo_data')\n",
    "print(\"Dataset structure:\")\n",
    "print(f\"  Train images: {len(list((data_path / 'images' / 'train').glob('*')))}\")\n",
    "print(f\"  Train labels: {len(list((data_path / 'labels' / 'train').glob('*')))}\")\n",
    "print(f\"  Val images: {len(list((data_path / 'images' / 'val').glob('*')))}\")\n",
    "print(f\"  Val labels: {len(list((data_path / 'labels' / 'val').glob('*')))}\")\n",
    "\n",
    "# Check data.yaml\n",
    "import yaml\n",
    "with open('yolo_data/data.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "    print(f\"\\nClasses: {config['names']}\")\n",
    "    print(f\"Number of classes: {config['nc']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0030b114",
   "metadata": {},
   "source": [
    "## 4. Train YOLOv8 Model\n",
    "\n",
    "Choose model size:\n",
    "- `yolov8n.pt` - Nano (fastest, 3.2M params) - **Recommended for Colab free tier**\n",
    "- `yolov8s.pt` - Small (11.2M params)\n",
    "- `yolov8m.pt` - Medium (25.9M params)\n",
    "- `yolov8l.pt` - Large (43.7M params) - Needs more GPU memory\n",
    "- `yolov8x.pt` - Extra Large (68.2M params) - Needs premium GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31ce205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Initialize model (downloads pretrained weights automatically)\n",
    "model = YOLO('yolov8n.pt')  # Change to 's', 'm', 'l', or 'x' for larger models\n",
    "\n",
    "# Train the model\n",
    "results = model.train(\n",
    "    data='yolo_data/data.yaml',\n",
    "    epochs=50,              # More epochs = better accuracy (50-100 recommended)\n",
    "    imgsz=640,              # Image size (640 is standard)\n",
    "    batch=16,               # Batch size (reduce if GPU memory issues)\n",
    "    device=0,               # Use GPU 0 (change to 'cpu' if no GPU)\n",
    "    workers=2,              # Data loading workers\n",
    "    patience=10,            # Early stopping patience\n",
    "    save=True,              # Save checkpoints\n",
    "    project='runs/detect',  # Project folder\n",
    "    name='road_damage',     # Run name\n",
    "    exist_ok=True,          # Overwrite existing\n",
    "    pretrained=True,        # Use pretrained weights\n",
    "    optimizer='AdamW',      # Optimizer\n",
    "    lr0=0.001,              # Initial learning rate\n",
    "    lrf=0.01,               # Final learning rate (lr0 * lrf)\n",
    "    momentum=0.937,         # SGD momentum/Adam beta1\n",
    "    weight_decay=0.0005,    # Optimizer weight decay\n",
    "    warmup_epochs=3,        # Warmup epochs\n",
    "    warmup_momentum=0.8,    # Warmup momentum\n",
    "    box=7.5,                # Box loss gain\n",
    "    cls=0.5,                # Class loss gain\n",
    "    dfl=1.5,                # DFL loss gain\n",
    "    hsv_h=0.015,            # HSV-Hue augmentation\n",
    "    hsv_s=0.7,              # HSV-Saturation augmentation\n",
    "    hsv_v=0.4,              # HSV-Value augmentation\n",
    "    degrees=0.0,            # Rotation augmentation\n",
    "    translate=0.1,          # Translation augmentation\n",
    "    scale=0.5,              # Scale augmentation\n",
    "    shear=0.0,              # Shear augmentation\n",
    "    perspective=0.0,        # Perspective augmentation\n",
    "    flipud=0.0,             # Vertical flip probability\n",
    "    fliplr=0.5,             # Horizontal flip probability\n",
    "    mosaic=1.0,             # Mosaic augmentation probability\n",
    "    mixup=0.0,              # Mixup augmentation probability\n",
    "    copy_paste=0.0,         # Copy-paste augmentation probability\n",
    "    verbose=True,           # Verbose output\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Training Complete!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6b8a12",
   "metadata": {},
   "source": [
    "## 5. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01159aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "best_model = YOLO('runs/detect/road_damage/weights/best.pt')\n",
    "\n",
    "# Validate on test set\n",
    "metrics = best_model.val(data='yolo_data/data.yaml')\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Validation Results:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"mAP@0.5: {metrics.box.map50:.4f}\")\n",
    "print(f\"mAP@0.5:0.95: {metrics.box.map:.4f}\")\n",
    "print(f\"Precision: {metrics.box.mp:.4f}\")\n",
    "print(f\"Recall: {metrics.box.mr:.4f}\")\n",
    "print(f\"\\nPer-class AP@0.5:\")\n",
    "for i, ap in enumerate(metrics.box.ap50):\n",
    "    class_name = ['Crack', 'Pothole', 'Severe_Damage'][i]\n",
    "    print(f\"  {class_name}: {ap:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c73347",
   "metadata": {},
   "source": [
    "## 6. Test on Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c13d60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import glob\n",
    "\n",
    "# Test on validation images\n",
    "test_images = glob.glob('yolo_data/images/val/*.jpg')[:5]  # First 5 images\n",
    "\n",
    "# Run inference\n",
    "results = best_model.predict(test_images, save=True, conf=0.25)\n",
    "\n",
    "# Display results\n",
    "print(\"Sample predictions:\")\n",
    "for i, r in enumerate(results):\n",
    "    print(f\"\\nImage {i+1}: {len(r.boxes)} detections\")\n",
    "    for box in r.boxes:\n",
    "        cls = int(box.cls[0])\n",
    "        conf = float(box.conf[0])\n",
    "        class_name = ['Crack', 'Pothole', 'Severe_Damage'][cls]\n",
    "        print(f\"  - {class_name}: {conf:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ccfbae",
   "metadata": {},
   "source": [
    "## 7. Export Model for Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4714ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to multiple formats\n",
    "best_model = YOLO('runs/detect/road_damage/weights/best.pt')\n",
    "\n",
    "# Export to ONNX (for production)\n",
    "best_model.export(format='onnx', dynamic=True, simplify=True)\n",
    "print(\"✓ Exported to ONNX\")\n",
    "\n",
    "# Export to TorchScript (for PyTorch deployment)\n",
    "best_model.export(format='torchscript')\n",
    "print(\"✓ Exported to TorchScript\")\n",
    "\n",
    "# Export to TensorFlow Lite (for mobile)\n",
    "try:\n",
    "    best_model.export(format='tflite')\n",
    "    print(\"✓ Exported to TensorFlow Lite\")\n",
    "except:\n",
    "    print(\"⚠ TFLite export requires tensorflow package\")\n",
    "\n",
    "print(\"\\nExported models are in: runs/detect/road_damage/weights/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9ba940",
   "metadata": {},
   "source": [
    "## 8. Download Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb481c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip all model files for download\n",
    "!zip -r trained_model.zip runs/detect/road_damage/weights/\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Model files ready for download!\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nDownload 'trained_model.zip' from the files panel on the left.\")\n",
    "print(\"\\nContents:\")\n",
    "print(\"  - best.pt          (Best model checkpoint)\")\n",
    "print(\"  - last.pt          (Last epoch checkpoint)\")\n",
    "print(\"  - best.onnx        (ONNX format for production)\")\n",
    "print(\"  - best.torchscript (TorchScript format)\")\n",
    "\n",
    "# Or download directly (in Colab)\n",
    "from google.colab import files\n",
    "files.download('trained_model.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140e1297",
   "metadata": {},
   "source": [
    "## 9. View Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4526bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training curves\n",
    "from IPython.display import Image as IPImage\n",
    "\n",
    "print(\"Training Results:\")\n",
    "results_images = [\n",
    "    'runs/detect/road_damage/results.png',\n",
    "    'runs/detect/road_damage/confusion_matrix.png',\n",
    "    'runs/detect/road_damage/val_batch0_pred.png'\n",
    "]\n",
    "\n",
    "for img_path in results_images:\n",
    "    if os.path.exists(img_path):\n",
    "        print(f\"\\n{img_path}:\")\n",
    "        display(IPImage(filename=img_path, width=800))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d394888",
   "metadata": {},
   "source": [
    "## 10. Quick Inference Test (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81a4d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a single image URL (optional)\n",
    "# Uncomment to test on a web image\n",
    "\n",
    "# image_url = 'https://example.com/road-image.jpg'\n",
    "# results = best_model.predict(image_url, save=True, conf=0.25)\n",
    "# results[0].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acce5ef",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps:\n",
    "\n",
    "1. **Download the trained model** (`trained_model.zip`)\n",
    "2. **Extract it to your local project** (in the same folder as detect_realtime.py)\n",
    "3. **Update model path** in `detect_realtime.py`:\n",
    "   ```python\n",
    "   model = YOLO('runs/detect/road_damage/weights/best.pt')\n",
    "   ```\n",
    "4. **Test real-time detection** locally:\n",
    "   ```bash\n",
    "   python detect_realtime.py --source 0 --api-key YOUR_GOOGLE_MAPS_KEY\n",
    "   ```\n",
    "5. **Deploy API server**:\n",
    "   ```bash\n",
    "   python api_server.py\n",
    "   ```\n",
    "\n",
    "## Training Tips:\n",
    "\n",
    "- **Low mAP?** Increase epochs (100+), try larger model (yolov8s/m)\n",
    "- **Overfitting?** Increase augmentation, reduce epochs\n",
    "- **GPU memory issues?** Reduce batch size (8 or 4)\n",
    "- **Slow training?** Use yolov8n, reduce image size (416 or 320)\n",
    "- **Want better accuracy?** Use yolov8m or yolov8l with 100 epochs\n",
    "\n",
    "**Expected Performance:**\n",
    "- YOLOv8n: 88-90% mAP@0.5 (~30 min training)\n",
    "- YOLOv8s: 90-92% mAP@0.5 (~45 min training)\n",
    "- YOLOv8m: 92-94% mAP@0.5 (~60 min training)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
