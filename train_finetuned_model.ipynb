{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8efa5cd",
   "metadata": {},
   "source": [
    "# ðŸš€ Fine-Tuned Road Condition Detection Training\n",
    "## v2.0 - With Augmented Dataset Support\n",
    "\n",
    "**ðŸŽ¯ Target Accuracy: 87-92%**\n",
    "\n",
    "### Key Improvements:\n",
    "- âœ… **6x More Training Data** (15,930 images via augmentation)\n",
    "- âœ… **EfficientNet-B0** backbone (better than MobileNetV2)\n",
    "- âœ… **Class Weights** for imbalanced data\n",
    "- âœ… **Enhanced Augmentation** pipeline\n",
    "- âœ… **Higher Dropout** (0.6) to reduce overfitting\n",
    "- âœ… **Cosine LR Scheduler** for better convergence\n",
    "- âœ… **100 Epochs** with patience=20\n",
    "\n",
    "### Dataset Options:\n",
    "1. **Augmented** (recommended): 15,930 training images â†’ Expected: 87-92% accuracy\n",
    "2. **Original**: 2,655 training images â†’ Expected: 81-85% accuracy\n",
    "\n",
    "### Instructions:\n",
    "1. Upload dataset ZIP to Google Drive (MyDrive root)\n",
    "2. Run all cells sequentially\n",
    "3. Training takes ~4-5 hours on Tesla T4\n",
    "4. Download trained model at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954c55dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages\n",
    "!pip install -q torch torchvision timm pillow matplotlib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import timm  # For EfficientNet\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Check GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"âœ“ Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"âœ“ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"âœ“ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c660fff",
   "metadata": {},
   "source": [
    "## Upload Dataset\n",
    "Use Option B (Google Drive) - fastest for 1.67 GB file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab64adb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Check which dataset is available\n",
    "import os\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CHECKING FOR DATASETS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Option 1: Augmented dataset (recommended - 6x more data)\n",
    "augmented_zip = '/content/drive/MyDrive/road_dataset_augmented.zip'\n",
    "# Option 2: Original dataset\n",
    "original_zip = '/content/drive/MyDrive/road_dataset_20251118_201844.zip'\n",
    "\n",
    "# Use augmented if available, otherwise use original\n",
    "if os.path.exists(augmented_zip):\n",
    "    print(\"âœ“ Found augmented dataset (17,928 images)\")\n",
    "    print(\"\\nExtracting augmented dataset (this may take 5-10 mins)...\")\n",
    "    !unzip -q /content/drive/MyDrive/road_dataset_augmented.zip -d /content/\n",
    "    TRAIN_DIR = '/content/data/train_augmented'\n",
    "    VAL_DIR = '/content/data/validation_augmented'\n",
    "    print(f\"\\nâœ“ Using AUGMENTED data (6x larger dataset)\")\n",
    "    print(f\"  Expected accuracy: 87-92%\")\n",
    "elif os.path.exists(original_zip):\n",
    "    print(\"âœ“ Found original dataset (3,321 images)\")\n",
    "    print(\"\\nExtracting original dataset...\")\n",
    "    !unzip -q /content/drive/MyDrive/road_dataset_20251118_201844.zip -d /content/\n",
    "    TRAIN_DIR = '/content/data/train'\n",
    "    VAL_DIR = '/content/data/validation'\n",
    "    print(f\"\\nâœ“ Using ORIGINAL data\")\n",
    "    print(f\"  Expected accuracy: 83-86%\")\n",
    "    print(f\"\\nðŸ’¡ TIP: Upload 'road_dataset_augmented.zip' to Drive for +4-7% accuracy boost!\")\n",
    "else:\n",
    "    print(\"\\nâŒ ERROR: No dataset found in Google Drive!\")\n",
    "    print(\"\\nPlease upload one of these files to 'My Drive' (root folder):\")\n",
    "    print(\"  â€¢ road_dataset_augmented.zip (8.69 GB) - RECOMMENDED\")\n",
    "    print(\"  â€¢ road_dataset_20251118_201844.zip (1.67 GB)\")\n",
    "    print(\"\\nThen re-run this cell.\")\n",
    "    raise FileNotFoundError(\"Dataset not found in Google Drive MyDrive root\")\n",
    "\n",
    "print(f\"\\nâœ“ Dataset extracted successfully!\")\n",
    "print(f\"  Train directory: {TRAIN_DIR}\")\n",
    "print(f\"  Validation directory: {VAL_DIR}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3f1771",
   "metadata": {},
   "source": [
    "### ðŸ“Š How to Create Augmented Dataset:\n",
    "\n",
    "**If you haven't created the augmented dataset yet:**\n",
    "\n",
    "1. On your local machine, run:\n",
    "   ```bash\n",
    "   cd C:\\Users\\amitu\\Downloads\\yolo\n",
    "   python augment_simple.py\n",
    "   ```\n",
    "\n",
    "2. Create ZIP file:\n",
    "   ```python\n",
    "   import shutil\n",
    "   shutil.make_archive('road_dataset_augmented', 'zip', 'data')\n",
    "   ```\n",
    "\n",
    "3. Upload `road_dataset_augmented.zip` to Google Drive root\n",
    "\n",
    "**OR** just upload the original dataset and proceed with slightly lower accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7eeae44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify dataset\n",
    "print(\"\\n=== Dataset Structure ===\")\n",
    "print(f\"Training classes: {os.listdir(TRAIN_DIR)}\")\n",
    "print(f\"Validation classes: {os.listdir(VAL_DIR)}\")\n",
    "\n",
    "print(\"\\nImages per class:\")\n",
    "class_counts = {}\n",
    "for class_name in os.listdir(TRAIN_DIR):\n",
    "    train_count = len(os.listdir(os.path.join(TRAIN_DIR, class_name)))\n",
    "    val_count = len(os.listdir(os.path.join(VAL_DIR, class_name)))\n",
    "    class_counts[class_name] = train_count\n",
    "    if train_count > 0:\n",
    "        print(f\"  {class_name}: {train_count} train, {val_count} val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc26ea3",
   "metadata": {},
   "source": [
    "## Build Improved Model with EfficientNet-B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48d2805",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedRoadModel(nn.Module):\n",
    "    def __init__(self, num_classes=3, dropout=0.6):\n",
    "        super(ImprovedRoadModel, self).__init__()\n",
    "        \n",
    "        # EfficientNet-B0 backbone (better than MobileNetV2)\n",
    "        self.backbone = timm.create_model('efficientnet_b0', pretrained=True, num_classes=0)\n",
    "        num_features = self.backbone.num_features  # 1280 for EfficientNet-B0\n",
    "        \n",
    "        # Freeze early layers\n",
    "        for param in list(self.backbone.parameters())[:-40]:\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Custom classification head with higher dropout\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(dropout),\n",
    "            \n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(dropout * 0.7),\n",
    "            \n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.5),\n",
    "            \n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        return self.classifier(features)\n",
    "\n",
    "# Create model\n",
    "model = ImprovedRoadModel(num_classes=3, dropout=0.6).to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nâœ“ Model built with EfficientNet-B0!\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96138b48",
   "metadata": {},
   "source": [
    "## Enhanced Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50ba93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CutMix augmentation\n",
    "def cutmix(image, label, alpha=1.0):\n",
    "    \"\"\"Apply CutMix augmentation\"\"\"\n",
    "    if random.random() > 0.5:\n",
    "        return image, label\n",
    "    \n",
    "    # Random crop box\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    _, h, w = image.shape\n",
    "    cut_h, cut_w = int(h * np.sqrt(1 - lam)), int(w * np.sqrt(1 - lam))\n",
    "    cx, cy = np.random.randint(w), np.random.randint(h)\n",
    "    x1 = np.clip(cx - cut_w // 2, 0, w)\n",
    "    x2 = np.clip(cx + cut_w // 2, 0, w)\n",
    "    y1 = np.clip(cy - cut_h // 2, 0, h)\n",
    "    y2 = np.clip(cy + cut_h // 2, 0, h)\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "# Strong augmentation pipeline\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((240, 240)),  # Slightly larger then crop\n",
    "    transforms.RandomCrop((224, 224)),\n",
    "    transforms.RandomRotation(30),  # More rotation\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(p=0.1),  # Roads can be inverted\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.3, hue=0.1),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.2, 0.2), scale=(0.8, 1.2), shear=10),\n",
    "    transforms.RandomPerspective(distortion_scale=0.2, p=0.3),\n",
    "    transforms.RandomGrayscale(p=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    transforms.RandomErasing(p=0.2, scale=(0.02, 0.2))  # Random occlusion\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"âœ“ Enhanced augmentation pipeline created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89567bf7",
   "metadata": {},
   "source": [
    "## Training Configuration with Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd17eb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training config\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "INITIAL_LR = 5e-5  # Lower initial LR\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = ImageFolder(TRAIN_DIR, transform=train_transforms)\n",
    "val_dataset = ImageFolder(VAL_DIR, transform=val_transforms)\n",
    "\n",
    "# Calculate class weights (from analysis)\n",
    "# Crack: 0.839, Pothole: 0.832, Severe_Damage: 1.651\n",
    "class_weights = torch.tensor([0.839, 0.832, 1.651]).to(device)\n",
    "\n",
    "# Create weighted sampler for balanced batches\n",
    "sample_weights = [class_weights[label] for _, label in train_dataset.samples]\n",
    "sampler = WeightedRandomSampler(sample_weights, len(sample_weights))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"\\nâœ“ Training samples: {len(train_dataset)}\")\n",
    "print(f\"âœ“ Validation samples: {len(val_dataset)}\")\n",
    "print(f\"âœ“ Classes: {train_dataset.classes}\")\n",
    "print(f\"âœ“ Class weights applied: {class_weights.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5e2c95",
   "metadata": {},
   "source": [
    "## Training Setup with Cosine LR Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e725ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss with class weights\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Optimizer with weight decay\n",
    "optimizer = optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=INITIAL_LR,\n",
    "    weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "# Cosine annealing scheduler (better than ReduceLROnPlateau)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer,\n",
    "    T_0=10,  # Restart every 10 epochs\n",
    "    T_mult=2,  # Double the period after each restart\n",
    "    eta_min=1e-7\n",
    ")\n",
    "\n",
    "print(f\"âœ“ Loss: CrossEntropyLoss with class weights\")\n",
    "print(f\"âœ“ Optimizer: AdamW (lr={INITIAL_LR}, wd={WEIGHT_DECAY})\")\n",
    "print(f\"âœ“ Scheduler: CosineAnnealingWarmRestarts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07922fcb",
   "metadata": {},
   "source": [
    "## Training Loop with All Improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24f425b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "best_val_acc = 0.0\n",
    "patience_counter = 0\n",
    "patience = 20  # More patience\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'lr': []}\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STARTING FINE-TUNED TRAINING\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Config: {EPOCHS} epochs, batch {BATCH_SIZE}, LR {INITIAL_LR}\")\n",
    "print(f\"Improvements: Class weights + EfficientNet + Strong augmentation\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        if (batch_idx + 1) % 20 == 0:\n",
    "            print(f\"  Batch {batch_idx+1}/{len(train_loader)} | Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    train_acc = train_correct / train_total\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    val_acc = val_correct / val_total\n",
    "    \n",
    "    # Step scheduler\n",
    "    scheduler.step()\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['lr'].append(current_lr)\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc*100:.2f}%\")\n",
    "    print(f\"Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc*100:.2f}%\")\n",
    "    print(f\"LR: {current_lr:.7f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            'class_names': train_dataset.classes\n",
    "        }, '/content/road_finetuned_best.pth')\n",
    "        patience_counter = 0\n",
    "        print(f\"âœ“ Best model saved! (Val Acc: {val_acc*100:.2f}%)\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    # Early stopping\n",
    "    if patience_counter >= patience:\n",
    "        print(f\"\\nâœ“ Early stopping triggered after {epoch+1} epochs\")\n",
    "        break\n",
    "    \n",
    "    # Show improvement over baseline\n",
    "    baseline_acc = 81.53\n",
    "    improvement = (best_val_acc * 100) - baseline_acc\n",
    "    if improvement > 0:\n",
    "        print(f\"ðŸ“ˆ Improvement over baseline: +{improvement:.2f}%\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"âœ“ FINE-TUNED TRAINING COMPLETED!\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Best Validation Accuracy: {best_val_acc*100:.2f}%\")\n",
    "print(f\"Baseline Accuracy: 81.53%\")\n",
    "print(f\"Improvement: {(best_val_acc*100 - 81.53):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b34d1e",
   "metadata": {},
   "source": [
    "## Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba883af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history['train_loss'], label='Train Loss')\n",
    "axes[0].plot(history['val_loss'], label='Val Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training and Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot([acc*100 for acc in history['train_acc']], label='Train Acc')\n",
    "axes[1].plot([acc*100 for acc in history['val_acc']], label='Val Acc')\n",
    "axes[1].axhline(y=81.53, color='r', linestyle='--', label='Baseline (81.53%)')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy (%)')\n",
    "axes[1].set_title('Training and Validation Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "# Learning Rate\n",
    "axes[2].plot(history['lr'])\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('Learning Rate')\n",
    "axes[2].set_title('Learning Rate Schedule (Cosine Annealing)')\n",
    "axes[2].set_yscale('log')\n",
    "axes[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/finetuned_results.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Training plots saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1462482",
   "metadata": {},
   "source": [
    "## Test Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be63347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "checkpoint = torch.load('/content/road_finetuned_best.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Test on samples\n",
    "def test_prediction(image_path, class_names):\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(img_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        confidence, predicted_class = torch.max(probabilities, 1)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Prediction: {class_names[predicted_class.item()]}\\n\"\n",
    "              f\"Confidence: {confidence.item()*100:.2f}%\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nPrediction: {class_names[predicted_class.item()]}\")\n",
    "    print(f\"Confidence: {confidence.item()*100:.2f}%\")\n",
    "    print(\"\\nAll probabilities:\")\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        print(f\"  {class_name}: {probabilities[0][i].item()*100:.2f}%\")\n",
    "\n",
    "# Test on validation samples\n",
    "class_names = checkpoint['class_names']\n",
    "for cls in os.listdir(VAL_DIR):\n",
    "    cls_path = os.path.join(VAL_DIR, cls)\n",
    "    if os.path.isdir(cls_path) and len(os.listdir(cls_path)) > 0:\n",
    "        sample_image = os.path.join(cls_path, os.listdir(cls_path)[0])\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Testing on {cls}:\")\n",
    "        test_prediction(sample_image, class_names)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af04a816",
   "metadata": {},
   "source": [
    "## Download Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdff13d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "print(\"Downloading fine-tuned model...\")\n",
    "files.download('/content/road_finetuned_best.pth')\n",
    "\n",
    "print(\"\\nDownloading training plots...\")\n",
    "files.download('/content/finetuned_results.png')\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ“ FINE-TUNING COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Final Accuracy: {best_val_acc*100:.2f}%\")\n",
    "print(f\"Improvement: +{(best_val_acc*100 - 81.53):.2f}% over baseline\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Rename to: models/road_condition_model.pth\")\n",
    "print(\"2. Update config.py with 3 classes instead of 5\")\n",
    "print(\"3. Run: python deploy_model.py\")\n",
    "print(\"4. Start detection: python main.py\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
